{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En estadśitica, la regresión lineales un modelo matemático usado para aproximar la relación de dependencia entre una variable dependiente $Y$, las variables independeintes $X_i$ y un termino aleatorio $C$. __[REF](https://es.wikipedia.org/wiki/Regresi%C3%B3n_lineal)__\n",
    "\n",
    "\\begin{align}\n",
    "Y_t = a_0 + a_1 X_1 + a_2 X_2 + ... + a_n X_n + C\n",
    "\\end{align}\n",
    "\n",
    "En la imágen siguiente podemos visualizar un ejemplo de esto. Se tienen $N$ cantidad de puntos en un plano cartesiano y se desea obtener una función que de manera optima pase por dichos puntos. En este caso, una linea basta para hacer el trabajo.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Linear_regression.svg/1200px-Linear_regression.svg.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo\n",
    "\n",
    "Dados los siguientes puntos, determinar la arquitectura que permita obtener el comportamiento mostrado\n",
    "\n",
    "| X | Y  |\n",
    "|---|----|\n",
    "| 0 | 0  |\n",
    "| 2 | 4  |\n",
    "| 4 | 8  |\n",
    "| 6 | 12 |\n",
    "| . | .  |\n",
    "| . | .  |\n",
    "| . | .  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, a simple vista se aprecia que la función que muestra este comportamiento es $f(x) = 2x$. Derivado de esto, podemos plantearnos usar unicamente una neurona con una entrada, una salida, y sin función de activación. Lo cual queda expresado como:\n",
    "\n",
    "\\begin{align}\n",
    "Y_{pred} = WX + b\n",
    "\\end{align}\n",
    "\n",
    "Notese que $W \\approx 2$ y $b \\approx 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hectorsab/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerias necesarias\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Importamos algunas funciones auxiliares\n",
    "from regresion_lineal import Data, print_all_tensors,obtener_wb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de entrenamiento\n",
    "\n",
    "A continuación se darán los datos de entrenamiento y prueba. \n",
    "\n",
    "La clase Data es una clase auxiliar que nos permite obtener sub conjunto de entrenamiento para cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  [ 0  2  4  6  8 10]\n",
      "Y:  [ 0  4  8 12 16 20]\n",
      "Xt: [1 3 5 7 9]\n",
      "Yt: [ 2  6 10 14 18]\n"
     ]
    }
   ],
   "source": [
    "# Datos de entrenamiento\n",
    "X = np.array([0,2,4,6,8,10]).T # Valores de entrada\n",
    "Y = 2*X # Valores esperados\n",
    "\n",
    "# Datos de prueba\n",
    "Xt = np.array([1,3,5,7,9]).T # Valores de entrada\n",
    "Yt = 2*Xt # Valores esperados\n",
    "\n",
    "# Definicion de las bases de datos \n",
    "train = Data(x=X,y=Y)\n",
    "test = Data(x=Xt,y=Yt)\n",
    "\n",
    "print('X:  {}'.format(X.T))\n",
    "print('Y:  {}'.format(Y.T))\n",
    "print('Xt: {}'.format(Xt.T))\n",
    "print('Yt: {}'.format(Yt.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0]]), array([[0]]))\n"
     ]
    }
   ],
   "source": [
    "# Si se desea obtener un sub conjunto de tamaño bs\n",
    "# se utiliza el siguiente metodo.\n",
    "print(train.next_batch(bs=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediante Grafos Computacionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeramente definimos las entradas a nuestro grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inp_x: Tensor(\"inp_x:0\", shape=(?, 1), dtype=float32)\n",
      "gt_y: Tensor(\"gt_y:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Definimos las entradas de informacion al grafo\n",
    "inp_x = tf.placeholder(tf.float32,shape=[None,1],name='inp_x')\n",
    "gt_y = tf.placeholder(tf.float32,shape=[None,1],name='gt_y')\n",
    "\n",
    "print('inp_x: {}'.format(inp_x))\n",
    "print('gt_y: {}'.format(gt_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se establece la arquitectura de nuestro red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Identity:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Definimos la arquitectura\n",
    "layer1 = tf.layers.dense(inputs=inp_x,units=1,name='layer1') # Neurona con una salida (units=1)\n",
    "y_pred = tf.identity(layer1) # Copia de la capa layer1\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos interesados en saber la calidad de las predicciones de nuestra arquitectura, por ello definimos la función de perdida que tendrá.\n",
    "\n",
    "\\begin{align}\n",
    "loss_i = (Y_i - Ŷ_i)^2\n",
    "\\end{align}\n",
    "\n",
    "Y el costo que tendrá es el valor promedio de cada función de perdida.\n",
    "\n",
    "\\begin{align}\n",
    "cost = \\frac{1}{n} \\sum_{i=0}^{n} loss_i\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: Tensor(\"loss:0\", shape=(?, 1), dtype=float32)\n",
      "cost: Tensor(\"cost:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "loss = tf.pow(gt_y - y_pred,2.,name='loss')\n",
    "cost = tf.reduce_mean(loss,name='cost')\n",
    "\n",
    "print('loss: {}'.format(loss))\n",
    "print('cost: {}'.format(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar a la red, debemos definir que método será utilizado. Seleccionamos el método de Adam, indicamos que la taza de aprendizaje sea de 0.0001 y que la función a minimizar es \"cost\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos la sesión donde correrá todo nuestro grafo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos aleatoriamente los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una función auxiliar que permitirá predecir los valores $Ŷ$ dados $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    # Predice los valores de y correspondientes a x.\n",
    "    # Args:\n",
    "    #    x (np.array): Valores X a los que se desea predecir Y.\n",
    "    #        Su forma debe de ser [None,1]\n",
    "    # Returns\n",
    "    #    pred (np.array): Regresa los valores Y predichos.\n",
    "    #        Su forma es de [None,1]\n",
    "    fd = {inp_x:x}\n",
    "    pred = sess.run(y_pred,feed_dict=fd)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una función auxiliar para entrenar a la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(iters,train_set,bs=1):\n",
    "    # Entrena a la red neuronal\n",
    "    # Args:\n",
    "    #    iters (int): Numero de iteraciones\n",
    "    #    train_set (Data): Base de datos con la que se entrenara\n",
    "    #    bs (int): Tamaño del sub set con el que se entrenara cada iteracion\n",
    "    pbar = tqdm(range(iters))\n",
    "    for i in pbar:\n",
    "        next_bs = train_set.next_batch(bs)\n",
    "        \n",
    "        fd = {inp_x:next_bs[0],gt_y:next_bs[1]}\n",
    "        cst,_ = sess.run([cost,optimizer],feed_dict=fd)\n",
    "        pbar.set_description('Cost: {:.4f}'.format(float(cst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos un subset ejemplos de la base de datos de prueba para visualizar las predicciones que tiene antes y despues de ser entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.next_batch(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predecimos los valores de $Ŷ$ dado $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTx: [[1 3 5 7 9]]\n",
      "GTy: [[ 2  6 10 14 18]]\n",
      "PRy: [[ -1.6547637  -4.964291   -8.273819  -11.583345  -14.892874 ]]\n"
     ]
    }
   ],
   "source": [
    "pred = predict(test_data[0])\n",
    "print('GTx: {}\\nGTy: {}\\nPRy: {}'.format(test_data[0].T,test_data[1].T,pred.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos durante 500 iteraciones usando la base de datos \"train\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cost: 869.3782: 100%|██████████| 500/500 [00:03<00:00, 148.42it/s]\n"
     ]
    }
   ],
   "source": [
    "train_nn(iters=500,train_set=train,bs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a predecir $Ŷ$ dado $X$ para ver la evolución de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTx: [[1 3 5 7 9]]\n",
      "GTy: [[ 2  6 10 14 18]]\n",
      "PRy: [[ -1.5735002  -4.8059464  -8.038392  -11.270838  -14.503284 ]]\n"
     ]
    }
   ],
   "source": [
    "pred = predict(test_data[0])\n",
    "print('GTx: {}\\nGTy: {}\\nPRy: {}'.format(test_data[0].T,test_data[1].T,pred.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los valores de $W$ y $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[-1.616223]]\n",
      "b: [0.04272277]\n"
     ]
    }
   ],
   "source": [
    "w,b = obtener_wb(sess=sess)\n",
    "\n",
    "print('W: {}'.format(w))\n",
    "print('b: {}'.format(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mediante Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "elayer1 = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epredict(inputs):\n",
    "    pred = elayer1(inputs)\n",
    "    return(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eloss(inputs,y):\n",
    "    y_pred = epredict(inputs)\n",
    "    loss = tf.pow(y-y_pred,2.)\n",
    "    return(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(inputs,y):\n",
    "    tf.GradientTape() as tape:\n",
    "        loss = eloss(inputs,y)\n",
    "    return(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
