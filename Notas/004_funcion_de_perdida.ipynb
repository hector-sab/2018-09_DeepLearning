{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función de Perdida\n",
    "\n",
    "Todos los algoritmos en Deep Learning dependen de minimizar alguna función, la *función objetivo*, que es conocida como la *función de perdida*. Una función de perdida nos permite medir que tan bien está prediciendo el resultado esperado un modelo predictivo.\n",
    "\n",
    "\n",
    "## Mean Square Error\n",
    "\n",
    "Utilizado en problemas de regresión. Conforme el valor del error aumente, mayor será la penalización.\n",
    "\n",
    "\\begin{align}\n",
    "MSE = \\frac{1}{n}\\sum^n_{i=1}(y_i-\\hat{y_i})^2\n",
    "\\end{align}\n",
    "\n",
    "## Cross-Entropy\n",
    "\n",
    "Utilizado en problemas de clasificación. Al igual que en MSE, la penalización aumenta conforme el error. Sin embargo, la penalización en esta función es más fuerte que la de MSE.\n",
    "\n",
    "\\begin{align}\n",
    "ACE = -\\frac{1}{n}\\sum^n_{i=1}log(\\frac{e^{f_{y_i}}}{\\sum_j e^{f_j}})\n",
    "\\end{align}\n",
    "\n",
    "Donde $y_i$ es el indicador de la clase que debería ser correcta, $f$ es el valor de cada clase obtenido por la red, y $j$ el indicador de los valores de las clases predichas.\n",
    "\n",
    "Notese quela operación interna del $log$ es la operación de softmax.\n",
    "\n",
    "\\begin{align}\n",
    "softmax = \\frac{e^{f_{y_i}}}{\\sum_j e^{f_j}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error\n",
    "def loss_mse(y,y_pred):\n",
    "    SE = (y-y_pred)**2\n",
    "    MSE = np.mean(SE)\n",
    "    return(MSE)\n",
    "\n",
    "def loss_mse_elem(y,y_pred):\n",
    "    SE = (y-y_pred)**2\n",
    "    MSE = np.mean(SE,axis=-1)\n",
    "    return(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Cross-Entropy\n",
    "def loss_ace(y,y_pred):\n",
    "    log = np.log(np.sum(y*y_pred,axis=-1))\n",
    "    ace = -1*np.mean(log)\n",
    "    return(ace)\n",
    "\n",
    "def loss_ace_elem(y,y_pred):\n",
    "    log = np.log(np.sum(y*y_pred,axis=-1))\n",
    "    ace = -1*log\n",
    "    return(ace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: Regresión\n",
    "\n",
    "Tenemos una red que quiere aproximar sus resultados a una función $f(x)$. Sus resultados están mostrados en *y_pred*. Debido a que queremos minimizar la distancia entre los valores predecidos y los valores reales, utilizamos *Mean Square Error* para determinar el error entre estos. Notese que mientras más alejados estén los valores de su valor real, MSE penaliza en mayor medida el error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores predecidos\n",
    "y_pred = np.array([[0.8],[2.4],[5.1],[8]])\n",
    "# Valores reales\n",
    "y = np.array([[1],[3],[5],[7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos el error utilizando MSE.\n",
    "\n",
    "$SE_0 = (1-0.8)^2 = 0.04$\n",
    "\n",
    "$MSE_{error} = (0.04 + 0.36 + 0.01 + 1)/4 = 0.35$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35250000000000004\n"
     ]
    }
   ],
   "source": [
    "mse = loss_mse(y,y_pred)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04 0.36 0.01 1.  ]\n"
     ]
    }
   ],
   "source": [
    "mse = loss_mse_elem(y,y_pred)\n",
    "\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Es posible utilizar Cross-Entropy para este caso? ¿Porqupe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: MSE vs Cross-Entropy\n",
    "\n",
    "Imaginemos que tenemos dos redes neuronales que predicen la probabilidad que tiene una persona a pertenecer a un partido partido politico-PRI, PAN, MORENA. Esta es una tarea de clasificación.\n",
    "\n",
    "\n",
    "Como base de datos tenemos la preferencia de tres personas.\n",
    "\n",
    "| PRI | PAN | MORENA|\n",
    "|-----|\n",
    "| 0 | 0 | 1 |\n",
    "| 0 | 1 | 0 |\n",
    "| 1 | 0 | 1 |\n",
    "\n",
    "La primera red tiene una predicción como la siguiente.\n",
    "\n",
    "| PRI | PAN | MORENA |\n",
    "|-----|\n",
    "| 0.3 | 0.3 | 0.4 |\n",
    "| 0.3 | 0.4 | 0.3 |\n",
    "| 0.2 | 0.2 | 0.7 |\n",
    "\n",
    "La segunda red tiene la siguiente predicción.\n",
    "\n",
    "| PRI | PAN | MORENA |\n",
    "|-----|\n",
    "| 0.1 | 0.2 | 0.7 |\n",
    "| 0.1 | 0.7 | 0.2 |\n",
    "| 0.3 | 0.4 | 0.3 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones red 1\n",
    "y_pred1 = np.array([[0.3,0.3,0.4],\n",
    "                   [0.3,0.4,0.3],\n",
    "                   [0.1,0.2,0.7]])\n",
    "\n",
    "# Predicciones red 2\n",
    "y_pred2 = np.array([[0.1,0.2,0.7],\n",
    "                    [0.1,0.7,0.2],\n",
    "                    [0.3,0.4,0.3]])\n",
    "\n",
    "# Valores reales\n",
    "y = np.array([[0,0,1],\n",
    "              [0,1,0],\n",
    "              [1,0,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un par de observaciones.\n",
    "\n",
    "#### Error de clasificación\n",
    "Ambas neuronas han predecido las primeras dos pertenencias correctamente, y la ultima incorrectamente, y las dos tienen un mismo error de clasificación a pesar de que la segunda tuvo una predicción más acercada a la realidad.\n",
    "\n",
    "Error de la red #1: 1/3\n",
    "\n",
    "Error de la red #2: 1/3\n",
    "\n",
    "#### Error Cuadrático Promedio\n",
    "Si calculamos el MSE de ambos resultados, este nos da valores apropiados. La red #1 presenta un error cuadrpatico promedio más grande que la red #2. Justo como debería de ser.\n",
    "\n",
    "Para la primera red y el primer elemento de los resultados, se calcula de la siguiente manera:\n",
    "$(0-0.3)^2 +(0-0.3)^2 + (1-0.4)^2 = 0.18$\n",
    "\n",
    "Que para calcular el MSE completo se procede como sigue:\n",
    "$(0.18 + 0.18 + 0.44)/3 = 0.27 $\n",
    "\n",
    "MSE de la red #1: 0.27\n",
    "\n",
    "MSE de la red #2: 0.11\n",
    "\n",
    "#### Error Cross-Entropy\n",
    "Sin embargo, al observar los resultados que obtenemos al utilizar cross-entropy, y a sabiendas del logaritmo utilizado, nos podemos dar cuenta de que el utilizar cross-entropy nos permite penalizar más fuertemente a las predicciones conforme a que tan alejadas estén de la clase real. Además, esta función nos ayuda a tener un mejor entrenamiento ya que los gradientes se ven disminuidos en menor proporción con respecto a MSE conforme se acercan las predicciones a su valor deseado. Por otro lado, notese la importancia que le da MSE a los valores que no corresponden a la clase correcta que fue incorrectamente predecida\n",
    "\n",
    "Para la primera red y el primer elemento de los resultados, se calcula de la siguiente manera:\n",
    "$-log(0.3)*0 -log(0.3)*0 -log(0.4)*1 = 0.92$\n",
    "\n",
    "Que para calcular el ACE completo se procede como sigue:\n",
    "$(0.92 + 0.92 + 2.3)/3 = 1.38$\n",
    "\n",
    "ACE de la red #1: 1.38\n",
    "\n",
    "ACE de la red #2: 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2688888888888889 0.11333333333333334\n",
      "1.3783888522474517 0.6391075640678003\n"
     ]
    }
   ],
   "source": [
    "# Mean Square Error Completo para la red 1 y 2\n",
    "mse1 = loss_mse(y,y_pred1)\n",
    "mse2 = loss_mse(y,y_pred2)\n",
    "\n",
    "# Average Cross-Entropy para la red 1 y 2\n",
    "ace1 = loss_ace(y,y_pred1)\n",
    "ace2 = loss_ace(y,y_pred2)\n",
    "\n",
    "print(mse1,mse2)\n",
    "print(ace1,ace2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18       0.18       0.44666667] [0.04666667 0.04666667 0.24666667]\n",
      "[0.91629073 0.91629073 2.30258509] [0.35667494 0.35667494 1.2039728 ]\n"
     ]
    }
   ],
   "source": [
    "# Square Error para cada elemento de los resultados en la red 1 y 2\n",
    "mse1 = loss_mse_elem(y,y_pred1)\n",
    "mse2 = loss_mse_elem(y,y_pred2)\n",
    "\n",
    "# Cross-Entropy para cada elemento de los resultados en la red 1 y 2\n",
    "ace1 = loss_ace_elem(y,y_pred1)\n",
    "ace2 = loss_ace_elem(y,y_pred2)\n",
    "\n",
    "print(mse1,mse2)\n",
    "print(ace1,ace2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
